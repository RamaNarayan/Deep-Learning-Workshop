{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision\n",
    "This Jupyter notebook was created for the 2018 AIS Deep Learning for Computer Vision Workshop for the 2018 AI Conference at UT Dallas and focuses on using deep learning models such as convolutional neural networks to perform interesting computer vision tasks such as style transfer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "Introduction on concepts,\n",
    "Workshop,\n",
    "Future directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding. - Wikipedia\n",
    "\n",
    "Computer vision concentrates on mimicking human vision right from perception to decision making. What is this? A bottle. How did you know that this is a bottle? Your brain is either trained or learnt by itself to interpret this as a bottle. Your eyes perceive the object, extract the features like size, shape, color,etc and your brain makes a decision. Boom. Computer vision through deep learning is the same process. We provide an input as an image to the Deep learning blackbox which I'll whiten it in a moment and boom it understands and makes a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "Deep learning is based on neural networks. 'Deep' refers to number of layers that data is getting transformed.There are multiple neural network architectures for deep learning but today we'll look just into convoluted neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convoluted neural networks\n",
    "Requires little preprocessing than the other image classification algorithms. This is because the network learns the filters by itself. Applies cross-correlation(not convolution!) to input. Naive approach will be to match each pixel to a pixel. What if we its a truncated, deformed or rotated image? CNN does not match pixel to pixel. Compares piece by piece which we call features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "2D array of values. (image required) How do we know where there will be a feature match in the new image? We try it out in all possible locations. Feature becomes a filter. A new 2D array is formed with the results - filtered image. Repeat the process for all features. The network learns what features to use by observing for what filter the neuron gets activated. At the end, tensor will have [image][o/p][o/p][filteredImagesActivationMaps]\n",
    "\n",
    "o/p = (W−F+2P)/S+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Layer\n",
    "Place where humongous computation takes place. Correlation of a feature with all possible positions in an image. One image is converted into stack of images.At the end, tensor will have [image][o/p][o/p][filteredImagesActivationMaps]\n",
    "\n",
    "o/p = (W−F+2P)/S+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function\n",
    "Determines when the neuron should fire. Common activation function includes sigmoid, tanh and Relu. Rectified Linear Units - a non linear activation function.\n",
    "f(x) = max(0,x)\n",
    "End result - Image stack with non negative values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "Shrink each mini-image in the image stack. Idea is that exact location of the feature in the neighborhood is not required.This is how we capture even when particular feature is rotated or tilted. All we care about is that if it exists. Reduces computation time and controls overfitting. There are various pooling methods available - Max Pooling, L2-norm pooling and Average pooling. Max pooling is selecting the max value in the neighbourhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Layer\n",
    "Each feature becomes a list of vote values.During training, higher weights will have a stronger vote.When new image is presented, whichever weight had a higher vote - those values are taken and averaged. How do you know the voting weights and the features in convolutional layer? - Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation\n",
    "Error - Expected - Actual. Performs gradient descent based on the error. Once a minima is reached, the values for feature and voting weights are settled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "A 4D Array. [batchSize][height][width][depth]\n",
    "Depth is usually 3 for color image (RGB) and 1 for gray scale image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "We will be using TensorFlow for this tutorial so let's go ahead and import it as well as some other libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution() uncommet to enable eager execution\n",
    "\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
